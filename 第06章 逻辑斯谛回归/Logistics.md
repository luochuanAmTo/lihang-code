逻辑斯谛回归是一种用于分类的模型。它可以用来预测某个输入数据属于哪一类
$$
\sigma(z) = \frac{1}{1 + e^{-z}}=\frac{e^{z}}{1 + e^{z}}
$$




#### 二分类情况

$$
P(Y=1|x) = \frac{\exp(w \cdot x)}{1 + \exp(w \cdot x)}
$$

$$
P(Y=0|x) = \frac{1}{1 + \exp(w \cdot x))}
$$

*P*(*Y*=1∣*x*) 表示在给定输入 x的条件下，输出 Y=1的概率。

x是输入特征向量。

w是模型参数（权重向量）。

Y是类别标签，取值为0或1。

#### 多分类情况

  第k类的概率
$$
P(Y=k | x)=\frac{\exp \left(w_{k} \cdot x\right)}{1+\sum_{k=1}^{K-1} \exp \left(w_{k} \cdot x\right)}, \quad k=1,2, \cdots, K-1
$$

第K类的概率
$$
P(Y=K | x)=\frac{1}{1+\sum_{k=1}^{K-1} \exp \left(w_{k} \cdot x\right)}
$$



*x* 是输入特征向量。

$w_k$是第 k 类的模型参数（权重向量）。

Y是类别标签，取值为 1,2,⋯ ,K是类别总数。

exp⁡(w⋅x)表示对线性组合 w⋅x取指数，结果是一个正数。指数函数的作用是将线性组合 w⋅x 映射到一个正数范围(0,+∞)，从而方便后续的概率计算。

这里，逻辑斯谛回归的核心思想是通过一个“S形函数”（也叫**逻辑函数**）将输入的线性组合（即特征的加权和）映射到0到1之间的概率值。这个概率值表示输入数据属于某一类的可能性。

 **x**：输入特征。比如图片的像素值

$w_k$：第k类的权重。模型通过学习得到这些权重。

$exp(w_k*x)$ :这是指数函数，用来将$w_k$*x线性组合转换为正数。

**分母**：，这是归一化项，$1+\sum_{k=1}^{K-1} \exp \left(w_{k} \cdot x\right)$确保所有类别的概率加起来等于1。这个公式计算的是输入x属于第k类的概率。

 

### 最大熵模型

$$
P_{w}(y | x)=\frac{1}{Z_{w}(x)} \exp \left(\sum_{i=1}^{n} w_{i} f_{i}(x, y)\right)
$$



  $f_i$(*x*,*y*) 是一个二值函数（通常取值为0或1），表示输入 x和输出 y是否满足某种特定关系。

 在图像分类中，$f_i(x,y)$可能表示“图像 x包含某个视觉特征且类别为 y

每个特征函数 $f_i(x,y)$对应一个权重 w_i,表示该特征对类别*y* 的重要性

w_i>0：特征 f_i(x,y)对类别 y 有正面影响。

w_i<0：特征 f_i(x,y)对类别 y有负面影响。

$\exp \left(\sum_{i=1}^{n} w_{i} f_{i}(x, y)\right)$

将特征函数和权重的线性组合映射到正数范围，确保概率非负。

最大熵模型的训练目标是找到一组权重 w_i，使得模型的条件概率分布 P_w(y∣x) 满足约束条件，同时熵最大。

通常使用优化算法（如梯度下降法或拟牛顿法）来求解

归一化因子$Z_w(x)$ 
$$
Z_{w}(x)=\sum_{y} \exp \left(\sum_{i=1}^{n} w_{i} f_{i}(x, y)\right)
$$


对所有可能的类别 y的指数项求和。确保条件概率分布 P_w(y∣x) 的和为1





