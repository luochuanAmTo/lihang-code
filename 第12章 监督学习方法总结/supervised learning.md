### 监督学习

监督学习的目标是学习一个从输入到输出的映射函数：f: X→Y

*X* 是输入空间（特征空间），Y是输出空间（标签空间）

监督学习主要包括以下三种任务类型：

（1）分类

​    限的类别集合，例如 Y={0,1}（二分类）或 Y={1,2,…,K}（多分类）

 （2）标注

​    为输入的每个部分分配一个标签。

- 词性标注：输入是一个句子，输出是每个单词的词性（如名词、动词等）。
- 命名实体识别：输入是一个句子，输出是每个单词是否为命名实体（如人名、地名等

​    (3) 回归

  预测连续的数值，房价预测：输入是房屋特征（如面积、位置等），输出是房价





### 模型的基本概念

在机器学习和统计学中，模型是用来描述数据之间的关系或进行预测的工具。模型可以分为两大类：**概率模型**和**非概率模型**。

1.**概率模型**：这类模型使用概率分布来描述输入和输出之间的关系。例如，朴素贝叶斯法和隐马尔可夫模型就是典型的概率模型。它们通过计算条件概率 P(Y∣X) 来进行预测。

2.**非概率模型**：这类模型不依赖于概率分布，而是直接通过一个函数 Y=f(X)来映射输入到输出。例如，感知机和支持向量机就是非概率模型。

根据模型的学习方式，模型还可以分为**判别模型**和**生成模型**

1.**判别模型**：这类模型直接学习输入 *X* 和输出 Y 之间的条件概率分布 P(Y∣X) 或决策函数 Y=f(X)。常见的判别模型包括感知机、支持向量机、逻辑回归、决策树等。

2.**生成模型**：这类模型首先学习输入 X和输出 Y的联合概率分布 P(X,Y)，然后通过贝叶斯定理推导出条件概率分布 P(Y∣X)。常见的生成模型包括朴素贝叶斯法和隐马尔可夫模型。

### 学习策略

在二类分类的监督学习中，支持向量机、逻辑斯谛回归与最大熵模型、提升方法各自使用合页损失函数、逻辑斯谛损失函数、指数损失函数，分别写为：


$$
[1-y f(x)]_{+}
$$

$$
\log[1+\exp (-y f(x))]
$$

$$
\exp (-y f(x))
$$

#### 1.合页损失函数

*y* 是真实标签（取值为 +1 或 -1）

*f*(*x*) 是模型对输入 x 的预测值（比如 SVM 的决策函数输出

[⋅]+ 表示“取正值”，即如果括号内的值小于 0，则结果为 0；否则取原值

SVM 的目标是找到一个分类边界，使得样本点到边界的“间隔”（margin）尽可能大

  **如果分类正确且远离边界**（比如 yf(x)≥1）：
损失为 0（因为已经很安全了，不需要优化）

  **如果分类正确但靠近边界**（比如 0<yf(x)<1）：
损失为 1−yf(x)，即鼓励模型让预测值 f(x) 远离边界

#### 2.逻辑斯蒂损失函数

*y* 是真实标签（+1 或 -1）

f(x)是模型的预测值（比如逻辑回归输出的概率的对数形式

**如果预测正确且置信度高**（比如 yf(x) 很大）：
exp⁡(−yf(x))接近 0，损失接近 log⁡(1+0)=0

