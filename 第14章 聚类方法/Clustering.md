### K-Means

#### 1.初始化

​     随机选择 K个数据点作为初始质心 {μ1,μ2,…,μK}

#### 2.分配数据点到簇

​    对于每个数据点 x，计算其与所有质心的距离：
$$
d(x, \mu_i) = \|x - \mu_i\|^2
$$
  数据点分配到距离最近的质心所在的簇：
$$
C_i = \{ x : \|x - \mu_i\|^2 \leq \|x - \mu_j\|^2 \text{ for all } j \neq i \}
$$

#### 3.更新质心

对于每个簇 Ci，重新计算其质心：
$$
\mu_i = \frac{1}{|C_i|} \sum_{x \in C_i} x
$$
如果质心不再发生变化，或者目标函数 J 的变化小于某个阈值，则算法收敛，停止迭代。



### 层次聚类

层次聚类（Hierarchical Clustering）是一种将数据对象组织成层次结构的聚类方法。其基本原理是通过逐步合并或分割数据点，形成一个树状结构（树形图），以便于理解和分析数据之间的关系。层次聚类的核心在于如何定义和计算数据点之间的相似性或距离，以及如何根据这些距离进行聚类。


##### 1.自底向上聚类（Agglomerative Clustering） 

​	初始化：将每个数据点视为一个独立的聚类。
​	计算距离：计算所有聚类之间的距离，通常使用欧几里得距离或曼哈顿距离。
​	合并聚类：找到距离最小的两个聚类，将它们合并为一个新的聚类。
​	更新距离矩阵：根据合并后的新聚类，更新距离矩阵。
​	重复：重复上述步骤，直到所有数据点合并为一个聚类，或达到预设的聚类数

**2.自顶向下聚类**

​	**初始化**：将所有数据点视为一个整体聚类。

​	**分割聚类**：根据某种标准（如距离或相似性）将当前聚类分割成两个或多个子聚类。

​	**重复**：对每个子聚类重复分割过程，直到每个数据点都成为一个独立的聚类。
